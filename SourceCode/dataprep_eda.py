# -*- coding: utf-8 -*-
"""Dataprep_EDA

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UNs9_WOd4JipsjIlR2ZRkAtVFrOB-Gms
"""

from google.colab import drive
drive.mount('/content/drive')

"""#Kfold Stratified Sampling (train,test,and valid sets) on Sample data"""

import os

prompts = []
labels = []

# Set the path to the directory containing the text files
directory = '/content/drive/MyDrive/data298A/shweta_prompts_parking_qa'

# Loop through all the files in the directory
for filename in os.listdir(directory):
    if filename.endswith(".txt"):
        filepath = os.path.join(directory, filename)
        with open(filepath, 'r') as f:
            lines = f.readlines()
            prompt = None
            label = None
            for i in range(len(lines)):
                # Check if the line contains the prompt
                if 'Question:' in lines[i]:
                    prompt_split = lines[i].strip().split('Question: ')
                    if len(prompt_split) >= 2:
                        prompt = prompt_split[1]
                        i += 1
                # Check if the line contains the answer label
                elif 'Answer:' in lines[i]:
                    label_split = lines[i].strip().split('Answer: ')
                    if len(label_split) >= 2:
                        label = label_split[1]
                        i += 1
                # If both the prompt and label are not None, add them to the list
                if prompt is not None and label is not None:
                    prompts.append(prompt)
                    labels.append(label)

if len(prompts) == 0:
    print("No prompts found in the directory.")
else:
    # check the length of prompts and labels again
    print(len(prompts), len(labels))
    print()

    # Split the data into training, validation, and test sets using stratified sampling
    from sklearn.model_selection import StratifiedKFold

    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

    train_prompts_len = []
    test_prompts_len = []
    val_prompts_len = []

    train_prompts_fold = {}
    train_labels_fold = {}
    test_prompts_fold = {}
    test_labels_fold = {}
    val_prompts_fold = {}
    val_labels_fold = {}

    for fold, (train_index, test_index) in enumerate(skf.split(prompts, labels)):
        train_prompts = [prompts[i] for i in train_index]
        train_labels = [labels[i] for i in train_index]
        test_prompts = [prompts[i] for i in test_index]
        test_labels = [labels[i] for i in test_index]

   
        # Split the training set further into training and validation sets
        val_size = len(train_prompts) // 10
        val_prompts = train_prompts[:val_size]
        val_labels = train_labels[:val_size]
        train_prompts = train_prompts[val_size:]
        train_labels = train_labels[val_size:]

        train_prompts_len.append(len(train_prompts))
        test_prompts_len.append(len(test_prompts))
        val_prompts_len.append(len(val_prompts))

        train_prompts_fold[fold] = train_prompts
        train_labels_fold[fold] = train_labels
        test_prompts_fold[fold] = test_prompts
        test_labels_fold[fold] = test_labels
        val_prompts_fold[fold] = val_prompts
        val_labels_fold[fold] = val_labels


        print("Fold: ", fold)
        print("Training Prompts: ", train_prompts[:3])
        print("Training Labels: ", train_labels[:3])
        print("Validation Prompts: ", val_prompts[:3])
        print("Validation Labels: ", val_labels[:3])
        print("Testing Prompts: ", test_prompts[:3])
        print("Testing Labels: ", test_labels[:3])

"""# Exploratory Data Analytics"""

def get_len(val):
  val_plen={}
  for f in val:
    plen=[]
    for p in val[f]:
      plen.append(len(p))
    val_plen[f] = plen
  return val_plen

train_prompts_len=get_len(train_prompts_fold)
train_labels_len=get_len(train_labels_fold)

from matplotlib import pyplot as plt
import numpy as np


# Creating histogram
fig, ax = plt.subplots(figsize =(10, 5))
ax.hist(train_prompts_len[0], bins=range(0, 100, 5))
 
# Show plot
plt.title("Train Prompts Length Histogram")
plt.show()

# Creating histogram
fig, ax = plt.subplots(figsize =(10, 5))
ax.hist(train_labels_len[0], bins=range(0, 100, 5))
 
# Show plot
plt.title("Train Labels Length Histogram")
plt.show()

print(len(train_prompts)/float(len(prompts)) * 100)
print(len(val_prompts)/float(len(prompts)) * 100)
print(len(test_prompts)/float(len(prompts)) * 100)



import numpy as np
import matplotlib.pyplot as plt
   
 
n=5
r = np.arange(n)
width = 0.25
  
  
plt.bar(r, train_prompts_len, color = 'b',
        width = width, edgecolor = 'black',
        label='Train prompts')
plt.bar(r + width, test_prompts_len, color = 'g',
        width = width, edgecolor = 'black',
        label='Test prompts')
plt.bar(r + 2*width, val_prompts_len, color = 'r',
        width = width, edgecolor = 'black',
        label='Val prompts')
  
plt.xlabel("K-Folds")
plt.ylabel("num of sets")
plt.title("Sample of stratified K-Fold splitting of SJSU Prompts data")
  
# plt.grid(linestyle='--')
plt.xticks(r + width/2,['K1','K2','K3','K4', 'K5'])
plt.legend()
  
plt.show()

import os
import matplotlib.pyplot as plt

prompts = []
count = {}

# Set the path to the directory containing the text files
directory = '/content/drive/MyDrive/data298A/shweta_prompts_parking_qa'

# Create empty lists for the file names and prompt counts
file_names = []
prompt_counts = []

# Loop through all the files in the directory
for filename in os.listdir(directory):
    if filename.endswith(".txt"):
        filepath = os.path.join(directory, filename)
        with open(filepath, 'r') as f:
            lines = f.readlines()
            prompt_count = 0
            for line in lines:
                # Check if the line contains the prompt
                if 'Question:' in line:
                    prompt_count += 1
            file_names.append(filename)
            prompt_counts.append(prompt_count)

# Create a bar graph of the prompt counts for each file
plt.bar(file_names, prompt_counts)
plt.title('Distribution of propmts on each sample file')
plt.xticks(rotation=90)
plt.xlabel('Text File Name')
plt.ylabel('Count of Prompts')
plt.show()